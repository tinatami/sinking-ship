{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import ppscore as pps\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier, plot_importance as plot_importance_lgbm\n",
    "from xgboost import XGBClassifier, plot_importance as plot_importance_xgb\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, precision_recall_curve, average_precision_score, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"titanic-train.csv\")\n",
    "test_data = pd.read_csv(\"titanic-test.csv\") # no ground truth available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PassengerId and Name irrelevant.\n",
    "\n",
    "Each column and its value counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in train_data.drop(['PassengerId', 'Name', 'Survived'], axis=1).columns:\n",
    "    print(train_data.loc[:, column].value_counts() ,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in train_data.columns:\n",
    "    s = \"Number of unique values in {}: {}\".format(column, len(train_data[column].unique()))\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = (train_data.isnull().sum())\n",
    "print(\"Missing values per column:\\n\", missing_values[missing_values > 0])\n",
    "print(\"\\n Percentage missing values per column:\\n\", missing_values[missing_values > 0]/train_data.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.Age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.Pclass.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.Embarked.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.Fare.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see:\n",
    "- 3 types of Pclass\n",
    "- 2 types of Sex\n",
    "- 0-5,8 Sibsp\n",
    "- 0-6 Parch\n",
    "- 3 types of Embarked (mostly S) + null\n",
    "- A lot of unique Ticket values\n",
    "- Lots of Cabin info missing\n",
    "- Age and Fare have high variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_df = pps.matrix(train_data)[['x', 'y', 'ppscore']].pivot(columns='x', index='y', values='ppscore')\n",
    "matrix_df = matrix_df.apply(lambda x: round(x, 2))\n",
    "\n",
    "sns.heatmap(matrix_df, vmin=0, vmax=1, cmap=\"Blues\", linewidths=0.75, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this PPS matrix, we can see: \n",
    "- Best univariate predictor of Survived: Ticket (0.19), Sex (0.13), Fare (0.09) \n",
    "\n",
    "Also: Cabin, Fare, Pclass, Ticket probably are related in some way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features we will use\n",
    "train_data_sub = train_data.drop([\"Name\", \"Cabin\", \"Ticket\", \"Survived\", \"PassengerId\"], axis=1)\n",
    "target = train_data.Survived\n",
    "\n",
    "train_data_sub.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn Age category into a categorical one\n",
    "train_data_sub.loc[train_data_sub.Age < 18, 'AgeCat'] = 'child'\n",
    "train_data_sub.loc[(train_data_sub.Age >= 18) & (train_data_sub.Age < 65), 'AgeCat'] = 'adult'\n",
    "train_data_sub.loc[train_data_sub.Age >= 65, 'AgeCat'] = 'senior'\n",
    "\n",
    "# Turn Fare category into a categorical one\n",
    "train_data_sub.loc[train_data_sub.Fare < 10, 'FareCat'] = 'cheap'\n",
    "train_data_sub.loc[(train_data_sub.Fare >= 10) & (train_data_sub.Age < 20), 'FareCat'] = 'fair'\n",
    "train_data_sub.loc[(train_data_sub.Fare >= 20) & (train_data_sub.Age < 30), 'FareCat'] = 'medium'\n",
    "train_data_sub.loc[(train_data_sub.Fare >= 30) & (train_data_sub.Age < 50), 'FareCat'] = 'pricy'\n",
    "train_data_sub.loc[train_data_sub.Fare >= 50, 'FareCat'] = 'expensive'\n",
    "\n",
    "# Drop the original Age column\n",
    "train_data_sub = train_data_sub.drop([\"Age\", \"Fare\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get categorical and numerical column names\n",
    "categorical_columns = train_data_sub.select_dtypes(include=['object']).columns\n",
    "numerical_columns = train_data_sub.select_dtypes(exclude=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Pipelines and hyper parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluates model's performance on the test set (which will be created in model_best_pipe)\n",
    "def model_eval_test(best_model_pipeline, X_test, y_test):\n",
    "    results = []\n",
    "    \n",
    "    predictions = best_model_pipeline.best_estimator_.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    \n",
    "    results.append(accuracy)\n",
    "    results.append(precision)\n",
    "    results.append(recall)\n",
    "    results.append(f1)\n",
    "    \n",
    "    print(\"\\n\\nTest set results using best classifier:\")\n",
    "    print(\"Accuracy:\", round(results[0], 3))\n",
    "    print(\"Precision:\", round(results[1], 3))\n",
    "    print(\"Recall:\", round(results[2], 3))\n",
    "    print(\"F1-Score:\", round(results[3], 3))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data\n",
    "numerical_transformer_1 = SimpleImputer(strategy='mean')\n",
    "numerical_transformer_2 = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer_1 = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "data_transformer_1 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer_1, numerical_columns),\n",
    "        ('cat', categorical_transformer_1, categorical_columns)\n",
    "    ])\n",
    "data_transformer_2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer_2, numerical_columns),\n",
    "        ('cat', categorical_transformer_1, categorical_columns)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_best_pipe(data, target, numerical_columns, categorical_columns):\n",
    "    \n",
    "    # Splitting original train_data into train and test\n",
    "    # Avoiding information leakage\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.10, random_state=1)\n",
    "\n",
    "    # Testing different data transformers \n",
    "    pipeline = Pipeline(steps=[('data_transformer', data_transformer_1), \n",
    "                           ('clf', SVC())]) \n",
    "\n",
    "    param_grid = [ \n",
    "                    {'data_transformer': [data_transformer_1, data_transformer_2],\n",
    "                     'clf': [RandomForestClassifier()],\n",
    "                     'clf__n_estimators': [int(x) for x in np.linspace(5, 30, num=15)],\n",
    "                     'clf__max_features': [None, \"sqrt\", \"log2\"],\n",
    "                     'clf__max_depth': [int(x) for x in np.linspace(3, 10, num=5)],\n",
    "                     'clf__random_state': [int(x) for x in np.linspace(1, 49, num=30)]},\n",
    "\n",
    "                    {'data_transformer': [data_transformer_1, data_transformer_2],\n",
    "                     'clf': [XGBClassifier(verbosity=0, use_label_encoder=False)],\n",
    "                     'clf__n_estimators': [int(x) for x in np.linspace(3, 15, num=10)],\n",
    "                     'clf__eta': np.linspace(0.1, 0.9), # learning rate\n",
    "                     'clf__max_depth': [int(x) for x in np.linspace(2, 7, num=5)],\n",
    "                     'clf__gamma': np.linspace(0.1, 1), # min loss reduction required to make further partition on leaf node of tree\n",
    "                     'clf__lambda': np.linspace(0.1, 1)} # L2 regularization term on weight\n",
    "                ]\n",
    "\n",
    "    # Metrics we will use\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1', 'average_precision', 'roc_auc']\n",
    "\n",
    "    # Stratification ensures dataset class ratio \n",
    "    cross_validator = StratifiedShuffleSplit(n_splits=5, train_size=0.8, test_size=0.2, random_state=1)\n",
    "\n",
    "    # Creating the randomized search cv object and fitting it\n",
    "    best_model_pipeline = RandomizedSearchCV(estimator=pipeline, param_distributions=param_grid, \n",
    "                                             n_iter=50, scoring=metrics, refit='accuracy', \n",
    "                                             n_jobs=-1, cv=cross_validator, random_state=1)\n",
    "\n",
    "    best_model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Results\n",
    "    print(\"Best Data Pipeline: \\n{}\".format(best_model_pipeline.best_estimator_[0]))\n",
    "    print(\"\\nBest Classifier: \\n {}\".format(best_model_pipeline.best_estimator_[1]))\n",
    "    print(\"\\nMean cross-validated score of the best_estimator: \\n {}\".format(best_model_pipeline.best_score_))\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, best_model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test data and best model's pipeline\n",
    "X_train, X_test, y_train, y_test, best_model_pipeline = model_best_pipe(train_data_sub, target, numerical_columns, categorical_columns)\n",
    "\n",
    "# Checking best model's performance on test data\n",
    "test_set_results = model_eval_test(best_model_pipeline, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
